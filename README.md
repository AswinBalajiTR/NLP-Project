# AI-Powered Gmail Job Application Tracker
### *Automated Email Classification â€¢ Job Entity Extraction â€¢ RAG Search â€¢ ChromaDB Storage â€¢ Streamlit Demo*

This project is an end-to-end **NLP pipeline** that reads your Gmail inbox, filters **job-related emails**, extracts structured metadata (company, role, date, status), stores them in a **vector database**, and finally allows you to **chat with your job emails** using RAG (Retrieval-Augmented Generation).

A **Streamlit demo app (`app.py`)** is included to run everything visually.

---

## ğŸš€ Features

- âœ” Gmail API email fetching  
- âœ” Job vs non-job classification (Classifier 1 performs best)  
- âœ” NER extraction (Company, Position, Date, Status, Link)  
- âœ” RAG + ChromaDB storage  
- âœ” Chat with your processed job emails  
- âœ” End-to-end Streamlit UI  

---

# ğŸ“¦ Installation & Setup

## 1ï¸âƒ£ Clone the Repository

```bash
git clone https://github.com/<your-username>/NLP-Project.git
cd NLP-Project/Code
```

---

## 2ï¸âƒ£ Install Requirements

Before running anything:

```bash
pip install -r requirements.txt
```

âš ï¸ **IMPORTANT:**  
Make sure you have a **local LLaMA model downloaded** (Ollama recommended)

Example:

```bash
ollama pull llama3
```

This is required for the RAG chat and some classifier logic.

---

## 3ï¸âƒ£ Set Up Gmail API (Google Cloud Console)

1. Go to: https://console.cloud.google.com  
2. Create a **new project**  
3. Enable **Gmail API**  
4. Go to **OAuth Consent Screen**
   - Select **External**
   - Add yourself as a **trusted user**
5. Go to **Credentials â†’ Create Credentials â†’ OAuth Client ID**
6. Choose **Desktop App**
7. Download `credentials.json`
8. Place it in:

```
NLP-Project/Code/credentials.json
```

---

# ğŸ§  Running the Pipeline

## â­ STEP 1 â€” Train the Classifier (Classifier 1)

```bash
cd "Classifier 1"
python training.py
```

Generates:

```
best_classifier.pkl
```

---

## â­ STEP 2 â€” Fetch Gmail Emails

```bash
cd ..
python gmail_read.py
```

Creates:

```
Data/gmail_subject_body_date.xlsx
```

---

## â­ STEP 3 â€” Classify Emails (job / non-job)

```bash
python predict.py
```

Outputs:

```
Data/mail_classified.xlsx
```

---

## â­ STEP 4 â€” Extract Entities (NER)

```bash
python ner.py
```

Outputs:

```
Data/mail_classified_llm_parsed.xlsx
```

---

## â­ STEP 5 â€” Store in ChromaDB (RAG)

```bash
python rag.py
```

This will:

- Embed emails using BGE or MiniLM  
- Create/update `chroma_store/`  
- Prepare data for semantic search + chat

---

## â­ STEP 6 â€” Run Streamlit Demo App

For a complete visual demo:

```bash
streamlit run app.py
```

This will open a full UI to:
- Fetch emails  
- Classify job vs non-job  
- Extract structured job info  
- Store into vector DB  
- Chat with your job emails  

---

# ğŸ§ª Example Use Cases

### ğŸ” â€œShow me all rejected applicationsâ€
### ğŸ—“ â€œWhen did I apply to Deloitte?â€
### ğŸ“Š â€œHow many companies responded last month?â€
### ğŸ¤– â€œSummarize all my job applications so farâ€

---

# ğŸ™Œ Contributors

- **Aswin Balaji TR**  
- **Siddharth**  
- **Rahul Arvind**  
- GWU DATS NLP Project (Fall 2025)

---
